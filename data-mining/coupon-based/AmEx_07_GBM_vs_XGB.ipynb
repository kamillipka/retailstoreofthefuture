{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demanding-uganda",
   "metadata": {},
   "source": [
    "# Training a model using GBM from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlike-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import xgboost as xgb \n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tight-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../amex-data/coupon-based/final_data/final_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "usual-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['coupon_id', 'customer_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confidential-qatar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['redemption_status', 'brand', 'category', 'coupon_used_x',\n",
       "       'discount_mean', 'discount_sum', 'item_counts', 'no_of_customers',\n",
       "       'price_mean', 'price_sum', 'quantity_mean', 'quantity_sum_x',\n",
       "       'tran_counts', 'campaign_type', 'campaign_duration', 'age_range',\n",
       "       'marital_status', 'rented', 'family_size', 'no_of_children',\n",
       "       'income_bracket', 'mean_discount', 'coupon_used_y', 'day', 'dow',\n",
       "       'no_of_items', 'month', 'mean_quantity', 'mean_price', 'ddiscount_sum',\n",
       "       'customer_id_count', 'quantity_sum_y', 'pprice_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "renewable-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-franchise",
   "metadata": {},
   "source": [
    "## SMOTE oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "military-passport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    54331\n",
       "1      527\n",
       "Name: redemption_status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.redemption_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "white-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(sampling_strategy=0.2)\n",
    "train_y = train['redemption_status']\n",
    "train_x = train.drop(['redemption_status'], axis=1)\n",
    "train_x, train_y = sm.fit_resample(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "registered-birth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    54331\n",
       "1    10866\n",
       "Name: redemption_status, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-disposition",
   "metadata": {},
   "source": [
    "## Training with GBM\n",
    "Using parameters from AutoML-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impaired-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opcja 1\n",
    "params = {\n",
    "    'n_estimators': 191,\n",
    "    'max_depth': 15,\n",
    "    'min_samples_split': 5,\n",
    "    'learning_rate': 0.01,\n",
    "    'loss': 'ls',\n",
    "    'max_leaf_nodes': 627\n",
    "}\n",
    "\n",
    "# opcja 2\n",
    "# params = {\n",
    "#     'n_estimators': 252,\n",
    "#     'max_depth': 15,\n",
    "#     'min_samples_split': 5,\n",
    "#     'learning_rate': 0.03,\n",
    "#     'loss': 'ls',\n",
    "#     'max_leaf_nodes': 469\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adjustable-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_depth=15, max_leaf_nodes=627,\n",
       "                          min_samples_split=5, n_estimators=191)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-riding",
   "metadata": {},
   "source": [
    "## Testing and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_y = test['redemption_status']\n",
    "# test_x = test.drop(['redemption_status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y = pd.Series(reg.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y = pred_y.apply(lambda x: 1 if x > 0.25 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(test_y, pred_y)\n",
    "# pd.crosstab(test_y, pred_y, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-donna",
   "metadata": {},
   "source": [
    "## Predict on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "double-cache",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75547\n",
       "1     2822\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_res = df['redemption_status']\n",
    "all_set = df.drop(['redemption_status'], axis=1)\n",
    "\n",
    "pred_all = pd.Series(reg.predict(all_set))\n",
    "pred_all = pred_all.apply(lambda x: 1 if x > 0.10 else 0)\n",
    "pred_all.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "psychological-directive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75456</td>\n",
       "      <td>2184</td>\n",
       "      <td>77640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>638</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>75547</td>\n",
       "      <td>2822</td>\n",
       "      <td>78369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0     1    All\n",
       "Actual                       \n",
       "0          75456  2184  77640\n",
       "1             91   638    729\n",
       "All        75547  2822  78369"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(real_res, pred_all, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "twelve-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     77640\n",
      "           1       0.23      0.88      0.36       729\n",
      "\n",
      "    accuracy                           0.97     78369\n",
      "   macro avg       0.61      0.92      0.67     78369\n",
      "weighted avg       0.99      0.97      0.98     78369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_res, pred_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-botswana",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intellectual-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ugolowic/workspace/.venv-ml/lib/python3.6/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:08:11] WARNING: /tmp/pip-build-keim6b1y/xgboost/build/temp.linux-x86_64-3.6/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.15, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(base_score=0.15)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wanted-august",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    77784\n",
       "1      585\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_res = df['redemption_status']\n",
    "all_set = df.drop(['redemption_status'], axis=1)\n",
    "\n",
    "pred_all_xgb = pd.Series(model.predict(all_set))\n",
    "pred_all_xgb.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-irish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "organized-receiver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77541</td>\n",
       "      <td>99</td>\n",
       "      <td>77640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243</td>\n",
       "      <td>486</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>77784</td>\n",
       "      <td>585</td>\n",
       "      <td>78369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0    1    All\n",
       "Actual                      \n",
       "0          77541   99  77640\n",
       "1            243  486    729\n",
       "All        77784  585  78369"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(real_res, pred_all_xgb, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "neutral-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     77640\n",
      "           1       0.83      0.67      0.74       729\n",
      "\n",
      "    accuracy                           1.00     78369\n",
      "   macro avg       0.91      0.83      0.87     78369\n",
      "weighted avg       1.00      1.00      1.00     78369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_res, pred_all_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-forum",
   "metadata": {},
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "welsh-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "empty-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('pickled_models'):\n",
    "    os.mkdir ('pickled_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "israeli-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled_models/scikit_regressor', 'wb') as f:\n",
    "    pickle.dump(reg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "pleased-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     77640\n",
      "           1       0.23      0.88      0.36       729\n",
      "\n",
      "    accuracy                           0.97     78369\n",
      "   macro avg       0.61      0.92      0.67     78369\n",
      "weighted avg       0.99      0.97      0.98     78369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test exported model\n",
    "with open('pickled_models/scikit_regressor', 'rb') as f:\n",
    "    preg_model = pickle.load(f)\n",
    "\n",
    "ppred_all = pd.Series(preg_model.predict(all_set))\n",
    "ppred_all = ppred_all.apply(lambda x: 1 if x > 0.10 else 0)\n",
    "print(classification_report(real_res, ppred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prepared-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19       1\n",
       "107      1\n",
       "138      1\n",
       "177      1\n",
       "181      1\n",
       "        ..\n",
       "78244    1\n",
       "78284    1\n",
       "78298    1\n",
       "78342    1\n",
       "78346    1\n",
       "Length: 2822, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppred_all.loc[ppred_all == 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
