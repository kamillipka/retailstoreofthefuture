{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unusual-blade",
   "metadata": {},
   "source": [
    "# Training with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, auc, precision_recall_curve, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_0408_0'\n",
    "train_file_path = os.path.join(data_dir, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_file_path)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.coupon_used.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['coupon_used']\n",
    "X_train = train.drop(['coupon_used'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_train.append(X_test)\n",
    "y_all = y_train.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curve(probs, preds, y, legend=''):\n",
    "    precision, recall, _ = precision_recall_curve(y, probs)\n",
    "    f1_, auc_ = f1_score(y, preds), auc(recall, precision)\n",
    "    # summarize scores\n",
    "    print(f'{legend}:\\nf1={round(f1_, 3)} auc={round(auc_, 3)}')\n",
    "    # plot the precision-recall curves\n",
    "    no_skill = len(y[y==1]) / len(y)\n",
    "    pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    pyplot.plot(recall, precision, marker='.', label='GBM')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('Recall')\n",
    "    pyplot.ylabel('Precision')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {\n",
    "    'n_estimators': 70,\n",
    "    'max_depth': 10,\n",
    "    'max_leaf_nodes': 994\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-enlargement",
   "metadata": {},
   "source": [
    "## 1. Training with no balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(**gbm_params)\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-county",
   "metadata": {},
   "source": [
    "#### 1.1. Evaluating on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-backing",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gbm.predict_proba(X_test)[:, 1]\n",
    "preds = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(probs, preds, y=y_test, legend='GBM trained on an unbalanced dataset, evaluated on the test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, preds, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-imperial",
   "metadata": {},
   "source": [
    "#### 1.2 Evaluating on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gbm.predict_proba(X_all)[:, 1]\n",
    "preds = gbm.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(probs, preds, y=y_all, legend='GBM trained on an unbalanced dataset, evaluated on the whole dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_all, preds, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_all, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-complex",
   "metadata": {},
   "source": [
    "#### 1.3. Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'pickled_model_gbm_no_balancing'), 'wb') as f:\n",
    "    pickle.dump(gbm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-injury",
   "metadata": {},
   "source": [
    "## 2. Training with balancing - SMOTE + Tomek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-three",
   "metadata": {},
   "source": [
    "#### 2.1. Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE! This takes very long\n",
    "smt = SMOTETomek()\n",
    "X_train_smt, y_train_smt = smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_smt.coupon_used.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-valley",
   "metadata": {},
   "source": [
    "#### 2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_smt = GradientBoostingClassifier(**gbm_params)\n",
    "gbm_smt.fit(X_train_smt, y_train_smt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-phenomenon",
   "metadata": {},
   "source": [
    "#### 2.3. Evaluating on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gbm_smt.predict_proba(X_test)[:, 1]\n",
    "preds = gbm_smt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(probs, preds, y=y_test,\n",
    "              legend='GBM trained on a balanced dataset (SMOTE+Tomek), evaluated on the test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, preds, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-medline",
   "metadata": {},
   "source": [
    "#### 2.4. Evaluating on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gbm_smt.predict_proba(X_all)[:, 1]\n",
    "preds = gbm_smt.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(probs, preds, y=y_all,\n",
    "              legend='GBM trained on a balanced dataset (SMOTE+Tomek), evaluated on the whole dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_all, preds, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_all, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-present",
   "metadata": {},
   "source": [
    "#### 2.5. Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'pickled_model_gbm_smote_tomek'), 'wb') as f:\n",
    "    pickle.dump(gbm_smt, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-malaysia",
   "metadata": {},
   "source": [
    "## 3. Training with balancing (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-foundation",
   "metadata": {},
   "source": [
    "#### 3.1. Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.5)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sm.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-orlando",
   "metadata": {},
   "source": [
    "#### 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_sm = GradientBoostingClassifier(**gbm_params)\n",
    "gbm_sm.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-words",
   "metadata": {},
   "source": [
    "#### 3.3 Evaluating on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gbm_sm.predict_proba(X_test)[:, 1]\n",
    "preds = gbm_sm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(probs, preds, y=y_test,\n",
    "              legend='GBM trained on a balanced dataset (SMOTE), evaluated on the test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, preds, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-wales",
   "metadata": {},
   "source": [
    "#### 3.4 Evaluating on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gbm_sm.predict_proba(X_all)[:, 1]\n",
    "preds = gbm_sm.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pr_curve(probs, preds, y=y_all,\n",
    "              legend='GBM trained on a balanced dataset (SMOTE), evaluated on the whole dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_all, preds, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_all, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-large",
   "metadata": {},
   "source": [
    "#### 3.5. Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-cyprus",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'pickled_model_gbm_smote'), 'wb') as f:\n",
    "    pickle.dump(gbm_sm, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
